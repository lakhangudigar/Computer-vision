{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/lakhangudigar/Computer-vision.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsX08zxfSRrZ",
        "outputId": "6840ff6d-1ca6-4974-f835-72f69070e284"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Computer-vision'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (3/3), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cvzone\n",
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szaasHr80wTu",
        "outputId": "eec6b70c-e4a9-4ca5-da1f-d5418bd2d386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cvzone\n",
            "  Downloading cvzone-1.6.1.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from cvzone) (4.10.0.84)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from cvzone) (1.26.4)\n",
            "Building wheels for collected packages: cvzone\n",
            "  Building wheel for cvzone (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cvzone: filename=cvzone-1.6.1-py3-none-any.whl size=26298 sha256=37f93267391eb23d400b2919daf9298ff90c16bb419f9c8c71195652b70b39ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/9f/b3/92e945ac4a71bf727a92463f38155cc5a4fa49c5010b38ec4c\n",
            "Successfully built cvzone\n",
            "Installing collected packages: cvzone\n",
            "Successfully installed cvzone-1.6.1\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.27-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.26.4)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.8.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (10.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.13.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.20.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.6)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.10-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.27-py3-none-any.whl (878 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m879.0/879.0 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.10-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: ultralytics-thop, ultralytics\n",
            "Successfully installed ultralytics-8.3.27 ultralytics-thop-2.0.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIcRzbmwBmqg"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import cv2\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "import cvzone"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explanation\n",
        "\n",
        "1. **`google.colab` (specifically `drive`)**:  \n",
        "   - **Purpose**: This module provides functions to interact with Google Drive directly within Google Colab.\n",
        "\n",
        "2. **`cv2` (OpenCV)**:  \n",
        "   - **Purpose**: OpenCV (Open Source Computer Vision Library) is a popular library for computer vision tasks.\n",
        "\n",
        "3. **`numpy` (imported as `np`)**:  \n",
        "   - **Purpose**: NumPy is a fundamental library for numerical operations and handling large, multi-dimensional arrays in Python.\n",
        "\n",
        "4. **`ultralytics` (specifically `YOLO`)**:  \n",
        "   - **Purpose**: This is a library from Ultralytics that provides implementations for the YOLO (You Only Look Once) model, which is a fast and efficient object detection model.\n",
        "\n",
        "     - `model.track()` or `model.detect()`: The YOLO model can detect objects and track them across frames. The model detects objects and provides bounding boxes, labels, and other properties for each object found.\n",
        "\n",
        "5. **`cvzone`**:  \n",
        "   - **Purpose**: CVZone is a Python library that builds on top of OpenCV and provides additional utilities for computer vision tasks, especially ones related to object tracking, detection, and interaction.\n"
      ],
      "metadata": {
        "id": "uVBfMpz3XEs_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/sample_data/coco.txt\",\"r\") as f:\n",
        "  class_name = f.read().splitlines()"
      ],
      "metadata": {
        "id": "_e50zKOBB15X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explanation\n",
        "\n",
        "This code reads class names from a text file called `coco.txt` and stores each line as an element in a list. Here’s a step-by-step explanation of what each part does:\n",
        "\n",
        "1. **`with open(\"/content/sample_data/coco.txt\",\"r\") as f`:**\n",
        "   - This opens the file `coco.txt` located in the `/content/sample_data/` directory.\n",
        "   - The `\"r\"` mode opens the file in read-only mode.\n",
        "   - The `with` statement ensures the file is automatically closed after reading, even if an error occurs, making it a safe way to handle files.\n",
        "\n",
        "2. **`f.read()`**:\n",
        "   - This reads the entire content of the file into a single string.\n",
        "\n",
        "3. **`.splitlines()`**:\n",
        "   - This method splits the string into a list of lines, where each line is an item in the list, without including newline characters (`\\n`).\n",
        "\n",
        "4. **`class_name`**:\n",
        "   - The list of class names is stored in the variable `class_name`.\n",
        "   - Each entry in the `class_name` list corresponds to an object class from the COCO dataset, such as \"person,\" \"car,\" etc., which is used to label objects detected by the YOLO model.\n",
        "\n",
        "In object detection, this list helps identify what each detected class ID represents. For example, if YOLO detects an object with a class ID of `0`, you can refer to `class_name[0]` to get the name of the detected class (e.g., \"person\")."
      ],
      "metadata": {
        "id": "MUhzsC3eYE0U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(\"/content/drive/MyDrive/path_to_your_file/yolov8m.pt\")"
      ],
      "metadata": {
        "id": "-t9LpUN8B_MC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Explanation\n",
        "- **`YOLO`**: This is the class from the Ultralytics library that sets up a YOLO model instance.\n",
        "\n",
        "- **`\"/content/drive/MyDrive/path_to_your_file/yolov8s.pt\"`**: This specifies the location and filename of the YOLOv8 weights file (in this case, `yolov8s.pt`), which contains all the pre-trained parameters required for running YOLOv8.\n",
        "\n",
        "Once initialized, this model instance `model` is ready to detect objects in images or video frames using the YOLOv8 architecture. The \"s\" in `yolov8s.pt` stands for \"small\" and reflects the model's size and speed; other options might include `yolov8n.pt` (nano), `yolov8m.pt` (medium), etc., each with different performance characteristics."
      ],
      "metadata": {
        "id": "tMJjVPctY3OQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture('/content/sample_data/m.avi')\n",
        "count = 0\n",
        "area = [(222,118),(194,337),(799,300),(728,112)]\n",
        "people_count = []"
      ],
      "metadata": {
        "id": "AyeIlvQICOK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Explanation:\n",
        "\n",
        "1. **`cap = cv2.VideoCapture('/content/sample_data/m.avi')`**:\n",
        "   - This line creates a video capture object named `cap` using OpenCV’s `VideoCapture` function, which is used to read a video file.\n",
        "   - The path `'/content/sample_data/m.avi'` indicates the location of the video file you want to analyze. This file is expected to be in the `sample_data` directory of your current environment (e.g., Google Colab).\n",
        "\n",
        "2. **`count = 0`**:\n",
        "   - This initializes a variable named `count` to zero. It will likely be used to keep track of the number of frames processed or to control the processing rate (e.g., skipping frames for performance reasons).\n",
        "\n",
        "3. **`area = [(222, 118), (194, 337), (799, 300), (728, 112)]`**:\n",
        "   - This creates a list named `area`, which contains tuples representing the coordinates of points that define a polygonal area (a region of interest) in the video frame.\n",
        "   - These coordinates can be used for object tracking or counting within a specific area, such as counting people who enter or exit that defined area.\n",
        "\n",
        "4. **`people_count = []`**:\n",
        "   - This initializes an empty list named `people_count`. It will be used to store unique identifiers (IDs) of people detected in the video.\n",
        "   - By maintaining this list, the program can count how many unique people have entered the defined area without double-counting anyone who appears in multiple frames.\n"
      ],
      "metadata": {
        "id": "G2XzHMYuZPCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = '/content/processed_output3.avi'\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "out = cv2.VideoWriter(output_path, fourcc, 10.0, (1020,500))"
      ],
      "metadata": {
        "id": "bPfgmhTvCS9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explanation:\n",
        "\n",
        "### What is .avi file?\n",
        "An .avi file is a multimedia container format used for storing video and audio data.\n",
        "\n",
        "### what is CODEC?\n",
        "XVID: An open-source codec that is a popular choice for creating AVI files.\n",
        "\n",
        "A codec (short for coder-decoder or compressor-decompressor) is a software or hardware tool used to encode and decode digital data streams, particularly audio and video. Codecs are essential for compressing files to save space and for decompressing them for playback or editing.\n",
        "\n",
        "### what is VideoWriter_fourcc function?\n",
        "The cv2.VideoWriter_fourcc function in OpenCV is used to specify the codec that will be used for encoding video files\n",
        "\n",
        "1. **`output_path = '/content/processed_output.avi'`**:\n",
        "   - This line defines a variable named `output_path` that stores the file path where the processed video will be saved. In this case, the processed video will be saved as `processed_output.avi` in the `/content` directory (common in environments like Google Colab).\n",
        "\n",
        "2. **`fourcc = cv2.VideoWriter_fourcc(*'XVID')`**:\n",
        "   - This line creates a FourCC code using OpenCV's `VideoWriter_fourcc` function.\n",
        "   - FourCC (Four Character Code) is a 4-byte code used to specify the video codec that will be used for encoding the output video.\n",
        "   - Here, `*'XVID'` specifies the XVID codec, which is a popular video codec that provides good compression and quality. The asterisk (*) unpacks the string into individual characters.\n",
        "\n",
        "3. **`out = cv2.VideoWriter(output_path, fourcc, 20.0, (1020, 500))`**:\n",
        "   - This line initializes a `VideoWriter` object named `out`. The `VideoWriter` object is used to write frames to a video file.\n",
        "   - The parameters passed to `VideoWriter` are:\n",
        "     - `output_path`: The path where the processed video will be saved.\n",
        "     - `fourcc`: The codec used for encoding the video (in this case, XVID).\n",
        "     - `10.0`: The frames per second (FPS) for the output video. This means the video will play back at 10 frames per second.\n",
        "     - `(1020, 500)`: The size of the video frames (width, height) that will be written to the output file. This must match the dimensions of the frames being processed.\n",
        "\n",
        "### Overall Purpose:\n",
        "This code snippet sets up the necessary components to save the processed video output. It specifies the output file path, selects the video codec, and defines the frame rate and resolution of the output video. This setup allows you to write the frames that are processed in your video analysis loop to a new video file.\n",
        "\n"
      ],
      "metadata": {
        "id": "zIbf0KTyZ-CF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's go through this code line-by-line for detailed explanation:\n",
        "\n",
        "```python\n",
        "# Initialize counter and ID mapping\n",
        "count = 0\n",
        "people_count = []\n",
        "id_map = {}\n",
        "custom_id = 1\n",
        "```\n",
        "- **count = 0**: This initializes a frame counter `count` to 0, which will be used later to control frame processing frequency.\n",
        "- **people_count = []**: This list will store unique tracking IDs for detected people to avoid double-counting.\n",
        "- **id_map = {}**: This dictionary will map tracker IDs (from the tracking model) to custom sequential IDs for each person.\n",
        "- **custom_id = 1**: This sets the starting value for assigning custom IDs to people detected in the frame.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "while True:\n",
        "    # Capture frame-by-frame\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "```\n",
        "- **while True**: This creates an infinite loop to process each video frame continuously.\n",
        "- **ret, frame = cap.read()**: Reads a frame from the video stream (`cap`). `ret` is a boolean flag that is `True` if a frame is successfully read; otherwise, it's `False`. `frame` contains the actual frame.\n",
        "- **if not ret: break**: If no frame is captured (e.g., at the end of the video), the loop breaks and processing stops.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "    count += 1\n",
        "    if count % 2 != 0:  # Skip every other frame\n",
        "        continue\n",
        "```\n",
        "- **count += 1**: This increments the frame counter by 1 for every frame read.\n",
        "- **if count % 2 != 0: continue**: This ensures only every second frame is processed by skipping odd-numbered frames. This helps reduce processing load and speed up performance by halving the frame rate.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "    # Resize frame and process with the model\n",
        "    frame = cv2.resize(frame, (1020, 500))\n",
        "    results = model.track(frame, persist=True)\n",
        "```\n",
        "- **frame = cv2.resize(frame, (1020, 500))**: Resizes the current frame to 1020x500 pixels to ensure consistent input size for the model.\n",
        "- **results = model.track(frame, persist=True)**: The tracking model processes the frame and returns detection results (bounding boxes, class IDs, track IDs, and confidence scores). The `persist=True` keeps the model's internal tracking state across frames.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "    # Check if there are detections\n",
        "    if results[0].boxes is not None and results[0].boxes.id is not None:\n",
        "```\n",
        "- **if results[0].boxes is not None and results[0].boxes.id is not None**: This checks if any objects were detected in the frame (i.e., `results[0].boxes` is not empty) and if they have valid tracking IDs (i.e., `results[0].boxes.id` is not empty).\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "        boxes = results[0].boxes.xyxy.int().cpu().tolist()\n",
        "        class_ids = results[0].boxes.cls.int().cpu().tolist()\n",
        "        track_ids = results[0].boxes.id.int().cpu().tolist()\n",
        "        confidences = results[0].boxes.conf.cpu().tolist()\n",
        "```\n",
        "- **boxes = results[0].boxes.xyxy.int().cpu().tolist()**: Extracts the bounding box coordinates (top-left x, y and bottom-right x, y) from the detected objects and converts them to integer format, then moves the data to CPU memory and converts it into a list.\n",
        "- **class_ids = results[0].boxes.cls.int().cpu().tolist()**: Extracts class IDs (e.g., 'person', 'car') and converts them to integers, moves them to CPU, and converts to a list.\n",
        "- **track_ids = results[0].boxes.id.int().cpu().tolist()**: Extracts the tracking IDs (unique identifiers for each detected object) and converts them to integers, moves them to CPU, and converts to a list.\n",
        "- **confidences = results[0].boxes.conf.cpu().tolist()**: Extracts the confidence scores (likelihood of correct detection) and moves them to CPU, then converts to a list.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "        for box, class_id, track_id, conf in zip(boxes, class_ids, track_ids, confidences):\n",
        "            c = class_name[class_id]\n",
        "            x1, y1, x2, y2 = box\n",
        "            cx = int(x1 + x2) // 2\n",
        "            cy = int(y1 + y2) // 2\n",
        "```\n",
        "- **for box, class_id, track_id, conf in zip(boxes, class_ids, track_ids, confidences)**: Iterates through all detected objects in the current frame, unpacking their bounding box, class ID, tracking ID, and confidence score.\n",
        "- **c = class_name[class_id]**: Converts the numeric class ID into a readable class name (e.g., 'person', 'car') using the `class_name` dictionary.\n",
        "- **x1, y1, x2, y2 = box**: Extracts the bounding box coordinates (top-left and bottom-right corners).\n",
        "- **cx = int(x1 + x2) // 2**: Computes the x-coordinate of the center of the bounding box.\n",
        "- **cy = int(y1 + y2) // 2**: Computes the y-coordinate of the center of the bounding box.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "            # Check if the detected object is a person and within the specified area\n",
        "            if 'person' in c:\n",
        "                result = cv2.pointPolygonTest(np.array(area, np.int32), (cx, cy), False)\n",
        "                if result >= 0:\n",
        "```\n",
        "- **if 'person' in c**: Checks if the detected object is classified as a person.\n",
        "- **result = cv2.pointPolygonTest(np.array(area, np.int32), (cx, cy), False)**: Uses OpenCV's `pointPolygonTest` function to check if the center of the detected object (`cx, cy`) lies within a defined polygonal area (`area`). If `result >= 0`, the point is inside the area.\n",
        "  \n",
        "---\n",
        "\n",
        "```python\n",
        "                    # Assign a unique ID if not already mapped\n",
        "                    if track_id not in id_map:\n",
        "                        id_map[track_id] = custom_id\n",
        "                        custom_id += 1\n",
        "```\n",
        "- **if track_id not in id_map**: Checks if this tracking ID has been seen before. If not, a custom ID is assigned.\n",
        "- **id_map[track_id] = custom_id**: Maps the current tracking ID to a custom sequential ID.\n",
        "- **custom_id += 1**: Increments the custom ID for the next new person.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "                    # Draw bounding box and ID\n",
        "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "                    cvzone.putTextRect(frame, f'ID-{id_map[track_id]}', (x1, y1), 1, 1)\n",
        "```\n",
        "- **cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)**: Draws a green rectangle around the detected person using their bounding box coordinates.\n",
        "- **cvzone.putTextRect(frame, f'ID-{id_map[track_id]}', (x1, y1), 1, 1)**: Draws the custom ID of the detected person near the top-left corner of the bounding box.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "                    # Update people count if ID is new\n",
        "                    if track_id not in people_count:\n",
        "                        people_count.append(track_id)\n",
        "```\n",
        "- **if track_id not in people_count**: If this is a new person (i.e., their tracking ID hasn't been counted yet), add their tracking ID to `people_count` to avoid counting them again.\n",
        "- **people_count.append(track_id)**: Adds the current tracking ID to the list of counted people.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "        # Display the people counter\n",
        "        p_counter = len(people_count)\n",
        "        cvzone.putTextRect(frame, f'People counter: {p_counter}', (50, 60), 2, 2)\n",
        "        cv2.polylines(frame, [np.array(area, np.int32)], True, (255, 0, 0), 2)\n",
        "```\n",
        "- **p_counter = len(people_count)**: Counts the total number of unique people detected so far.\n",
        "- **cvzone.putTextRect(frame, f'People counter: {p_counter}', (50, 60), 2, 2)**: Displays the total people count on the frame at position (50, 60).\n",
        "- **cv2.polylines(frame, [np.array(area, np.int32)], True, (255, 0, 0), 2)**: Draws the specified polygonal area on the frame in blue to visually show the region where people are being counted.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "        # Write frame to output video\n",
        "        out.write(frame)\n",
        "```\n",
        "- **out.write(frame)**: Writes the current frame (with bounding boxes, IDs, and counters) to the output video file.\n",
        "\n",
        "---\n",
        "\n",
        "```python\n",
        "# Release resources\n",
        "cap.release()\n",
        "out.release()\n",
        "print(\"Video saved as:\", output_path)\n",
        "```\n",
        "- **cap.release()**: Releases the video capture object (`cap`) to free up system resources.\n",
        "- **out.release()**: Releases the video writer object (`out`) used to save the output video.\n",
        "- **print(\"Video saved as:\", output_path)**: Prints a message showing the file path\n",
        "\n",
        " of the saved video, indicating that the video processing has been completed successfully.\n",
        "\n",
        "This entire code is part of an object detection and tracking application, where people are detected and tracked in video frames. The code ensures that each person is uniquely identified and counted only once, and the results are visualized and saved to a new video file."
      ],
      "metadata": {
        "id": "y2EiwUvTdIc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize counter and ID mapping\n",
        "count = 0\n",
        "people_count = []\n",
        "id_map = {}\n",
        "custom_id = 1\n",
        "\n",
        "while True:\n",
        "    # Capture frame-by-frame\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    count += 1\n",
        "    if count % 2 != 0:  # Skip every other frame\n",
        "        continue\n",
        "\n",
        "    # Resize frame and process with the model\n",
        "    frame = cv2.resize(frame, (1020, 500))\n",
        "    results = model.track(frame, persist=True)\n",
        "\n",
        "    # Check if there are detections\n",
        "    if results[0].boxes is not None and results[0].boxes.id is not None:\n",
        "        boxes = results[0].boxes.xyxy.int().cpu().tolist()\n",
        "        class_ids = results[0].boxes.cls.int().cpu().tolist()\n",
        "        track_ids = results[0].boxes.id.int().cpu().tolist()\n",
        "        confidences = results[0].boxes.conf.cpu().tolist()\n",
        "\n",
        "        for box, class_id, track_id, conf in zip(boxes, class_ids, track_ids, confidences):\n",
        "            c = class_name[class_id]\n",
        "            x1, y1, x2, y2 = box\n",
        "            cx = int(x1 + x2) // 2\n",
        "            cy = int(y1 + y2) // 2\n",
        "\n",
        "            # Check if the detected object is a person and within the specified area\n",
        "            if 'person' in c:\n",
        "                result = cv2.pointPolygonTest(np.array(area, np.int32), (cx, cy), False)\n",
        "                if result >= 0:\n",
        "                    # Assign a unique ID if not already mapped\n",
        "                    if track_id not in id_map:\n",
        "                        id_map[track_id] = custom_id\n",
        "                        custom_id += 1\n",
        "\n",
        "                    # Draw bounding box and ID\n",
        "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "                    cvzone.putTextRect(frame, f'ID-{id_map[track_id]}', (x1, y1), 1, 1)\n",
        "\n",
        "                    # Update people count if ID is new\n",
        "                    if track_id not in people_count:\n",
        "                        people_count.append(track_id)\n",
        "\n",
        "        # Display the people counter\n",
        "        p_counter = len(people_count)\n",
        "        cvzone.putTextRect(frame, f'People counter: {p_counter}', (50, 60), 2, 2)\n",
        "        cv2.polylines(frame, [np.array(area, np.int32)], True, (255, 0, 0), 2)\n",
        "\n",
        "        # Write frame to output video\n",
        "        out.write(frame)\n",
        "\n",
        "# Release resources\n",
        "cap.release()\n",
        "out.release()\n",
        "print(\"Video saved as:\", output_path)\n"
      ],
      "metadata": {
        "id": "8wiO1u_fDIyD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "863c21e9-1011-4827-f845-bb7e800625bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 320x640 11 persons, 23.8ms\n",
            "Speed: 2.3ms preprocess, 23.8ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 1 elephant, 22.8ms\n",
            "Speed: 2.6ms preprocess, 22.8ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 22.9ms\n",
            "Speed: 2.5ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 22.9ms\n",
            "Speed: 3.7ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 22.9ms\n",
            "Speed: 3.0ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 persons, 22.9ms\n",
            "Speed: 3.4ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 22.9ms\n",
            "Speed: 2.3ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 23.0ms\n",
            "Speed: 2.7ms preprocess, 23.0ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 22.8ms\n",
            "Speed: 2.4ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 22.9ms\n",
            "Speed: 2.6ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 22.9ms\n",
            "Speed: 2.3ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 22.9ms\n",
            "Speed: 3.2ms preprocess, 22.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 22.9ms\n",
            "Speed: 2.5ms preprocess, 22.9ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 22.9ms\n",
            "Speed: 3.2ms preprocess, 22.9ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 25.5ms\n",
            "Speed: 3.5ms preprocess, 25.5ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 22.9ms\n",
            "Speed: 2.6ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 22.8ms\n",
            "Speed: 2.7ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 persons, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 1 chair, 22.9ms\n",
            "Speed: 2.5ms preprocess, 22.9ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 22.9ms\n",
            "Speed: 2.4ms preprocess, 22.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 22.8ms\n",
            "Speed: 3.5ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 22.9ms\n",
            "Speed: 2.6ms preprocess, 22.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 22.9ms\n",
            "Speed: 2.5ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 22.9ms\n",
            "Speed: 3.0ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 23.1ms\n",
            "Speed: 3.1ms preprocess, 23.1ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 23.0ms\n",
            "Speed: 3.4ms preprocess, 23.0ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 22.9ms\n",
            "Speed: 4.5ms preprocess, 22.9ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 22.9ms\n",
            "Speed: 4.0ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 22.8ms\n",
            "Speed: 2.4ms preprocess, 22.8ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 persons, 22.8ms\n",
            "Speed: 2.3ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 persons, 22.9ms\n",
            "Speed: 2.6ms preprocess, 22.9ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 22.9ms\n",
            "Speed: 2.5ms preprocess, 22.9ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 22.9ms\n",
            "Speed: 2.5ms preprocess, 22.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 22.9ms\n",
            "Speed: 2.4ms preprocess, 22.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 22.8ms\n",
            "Speed: 3.6ms preprocess, 22.8ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 22.9ms\n",
            "Speed: 2.5ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 12 persons, 22.9ms\n",
            "Speed: 2.5ms preprocess, 22.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 13 persons, 22.9ms\n",
            "Speed: 4.1ms preprocess, 22.9ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 23.0ms\n",
            "Speed: 3.3ms preprocess, 23.0ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 22.9ms\n",
            "Speed: 3.8ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 22.9ms\n",
            "Speed: 3.5ms preprocess, 22.9ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 22.8ms\n",
            "Speed: 2.7ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 12 persons, 22.9ms\n",
            "Speed: 3.8ms preprocess, 22.9ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 12 persons, 22.9ms\n",
            "Speed: 3.5ms preprocess, 22.9ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 22.9ms\n",
            "Speed: 2.5ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 22.9ms\n",
            "Speed: 2.4ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 12 persons, 22.9ms\n",
            "Speed: 2.4ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 12 persons, 22.9ms\n",
            "Speed: 2.5ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 12 persons, 22.9ms\n",
            "Speed: 2.6ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 12 persons, 22.9ms\n",
            "Speed: 4.1ms preprocess, 22.9ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 22.9ms\n",
            "Speed: 4.4ms preprocess, 22.9ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 23.8ms\n",
            "Speed: 2.9ms preprocess, 23.8ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 22.9ms\n",
            "Speed: 2.6ms preprocess, 22.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 22.8ms\n",
            "Speed: 2.5ms preprocess, 22.8ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 22.9ms\n",
            "Speed: 2.5ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 12 persons, 22.9ms\n",
            "Speed: 3.7ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 12 persons, 22.9ms\n",
            "Speed: 3.0ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 12 persons, 22.9ms\n",
            "Speed: 3.3ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 23.2ms\n",
            "Speed: 3.1ms preprocess, 23.2ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 22.9ms\n",
            "Speed: 2.9ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 skateboard, 22.9ms\n",
            "Speed: 3.6ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 skateboard, 22.9ms\n",
            "Speed: 3.3ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 skateboard, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 skateboard, 23.0ms\n",
            "Speed: 4.7ms preprocess, 23.0ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 12 persons, 1 skateboard, 23.0ms\n",
            "Speed: 3.8ms preprocess, 23.0ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 12 persons, 1 skateboard, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 12 persons, 1 skateboard, 22.8ms\n",
            "Speed: 2.7ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 12 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.7ms preprocess, 22.9ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 12 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.0ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 12 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.7ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 12 persons, 1 umbrella, 23.1ms\n",
            "Speed: 2.9ms preprocess, 23.1ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 12 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.6ms preprocess, 22.9ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 13 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.4ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 14 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.6ms preprocess, 22.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 14 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.6ms preprocess, 22.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 14 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 14 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.6ms preprocess, 22.9ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 14 persons, 1 umbrella, 23.6ms\n",
            "Speed: 3.6ms preprocess, 23.6ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 13 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.4ms preprocess, 22.9ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 12 persons, 1 umbrella, 23.0ms\n",
            "Speed: 2.8ms preprocess, 23.0ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 22.9ms\n",
            "Speed: 5.6ms preprocess, 22.9ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 12 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 12 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 12 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.9ms preprocess, 22.9ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 22.9ms\n",
            "Speed: 4.8ms preprocess, 22.9ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.1ms preprocess, 22.9ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 1 umbrella, 26.3ms\n",
            "Speed: 4.6ms preprocess, 26.3ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 persons, 1 umbrella, 24.2ms\n",
            "Speed: 2.9ms preprocess, 24.2ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 persons, 1 umbrella, 1 skateboard, 23.2ms\n",
            "Speed: 2.9ms preprocess, 23.2ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 1 umbrella, 1 skateboard, 22.9ms\n",
            "Speed: 3.1ms preprocess, 22.9ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 1 umbrella, 1 skateboard, 22.9ms\n",
            "Speed: 3.0ms preprocess, 22.9ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.2ms preprocess, 22.9ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 persons, 1 umbrella, 22.9ms\n",
            "Speed: 6.0ms preprocess, 22.9ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.0ms preprocess, 22.9ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 1 umbrella, 23.0ms\n",
            "Speed: 3.6ms preprocess, 23.0ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 1 umbrella, 23.0ms\n",
            "Speed: 3.1ms preprocess, 23.0ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 1 umbrella, 25.8ms\n",
            "Speed: 2.9ms preprocess, 25.8ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 1 umbrella, 23.7ms\n",
            "Speed: 3.8ms preprocess, 23.7ms inference, 4.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.9ms preprocess, 22.9ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 1 umbrella, 24.5ms\n",
            "Speed: 2.9ms preprocess, 24.5ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.0ms preprocess, 22.9ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.9ms preprocess, 22.9ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 1 umbrella, 25.4ms\n",
            "Speed: 2.6ms preprocess, 25.4ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 22.9ms\n",
            "Speed: 5.1ms preprocess, 22.9ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 1 suitcase, 22.9ms\n",
            "Speed: 4.3ms preprocess, 22.9ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 1 suitcase, 27.0ms\n",
            "Speed: 2.9ms preprocess, 27.0ms inference, 3.2ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 12 persons, 1 umbrella, 29.7ms\n",
            "Speed: 2.9ms preprocess, 29.7ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 12 persons, 1 umbrella, 23.8ms\n",
            "Speed: 2.7ms preprocess, 23.8ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 12 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.4ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 13 persons, 1 umbrella, 23.5ms\n",
            "Speed: 2.8ms preprocess, 23.5ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 13 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 12 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.5ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.5ms preprocess, 22.9ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.6ms preprocess, 22.9ms inference, 5.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.6ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.0ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 22.8ms\n",
            "Speed: 2.6ms preprocess, 22.8ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.6ms preprocess, 22.9ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 22.9ms\n",
            "Speed: 4.5ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 22.9ms\n",
            "Speed: 2.4ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 22.9ms\n",
            "Speed: 3.4ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 22.9ms\n",
            "Speed: 3.6ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 skis, 22.9ms\n",
            "Speed: 2.6ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 skis, 22.9ms\n",
            "Speed: 2.5ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 22.9ms\n",
            "Speed: 3.1ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 23.0ms\n",
            "Speed: 3.0ms preprocess, 23.0ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 22.9ms\n",
            "Speed: 4.1ms preprocess, 22.9ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.5ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.6ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.9ms preprocess, 22.9ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.7ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.9ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.4ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.9ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.1ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 23.6ms\n",
            "Speed: 2.8ms preprocess, 23.6ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.3ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.7ms preprocess, 22.9ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 23.0ms\n",
            "Speed: 3.4ms preprocess, 23.0ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.2ms preprocess, 22.9ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 1 umbrella, 23.0ms\n",
            "Speed: 4.3ms preprocess, 23.0ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.6ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.2ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.1ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.6ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 13 persons, 1 umbrella, 23.4ms\n",
            "Speed: 2.9ms preprocess, 23.4ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 22.8ms\n",
            "Speed: 2.7ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 22.8ms\n",
            "Speed: 3.5ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 23.4ms\n",
            "Speed: 2.9ms preprocess, 23.4ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 11 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.9ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 1 umbrella, 23.2ms\n",
            "Speed: 3.1ms preprocess, 23.2ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.7ms preprocess, 22.9ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.0ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.9ms preprocess, 22.9ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.5ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.8ms\n",
            "Speed: 2.7ms preprocess, 22.8ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.5ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.4ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.1ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.5ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.5ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 persons, 1 umbrella, 23.6ms\n",
            "Speed: 2.6ms preprocess, 23.6ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 persons, 1 umbrella, 23.3ms\n",
            "Speed: 3.1ms preprocess, 23.3ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.9ms preprocess, 22.9ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 persons, 1 umbrella, 22.8ms\n",
            "Speed: 3.5ms preprocess, 22.8ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.7ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 1 umbrella, 22.8ms\n",
            "Speed: 3.7ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 persons, 1 umbrella, 22.8ms\n",
            "Speed: 3.2ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 persons, 1 umbrella, 23.1ms\n",
            "Speed: 2.8ms preprocess, 23.1ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 persons, 1 umbrella, 22.8ms\n",
            "Speed: 3.4ms preprocess, 22.8ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 persons, 1 umbrella, 23.0ms\n",
            "Speed: 2.7ms preprocess, 23.0ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 persons, 1 umbrella, 22.8ms\n",
            "Speed: 2.6ms preprocess, 22.8ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 1 umbrella, 22.8ms\n",
            "Speed: 2.7ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 1 umbrella, 23.6ms\n",
            "Speed: 2.6ms preprocess, 23.6ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 10 persons, 1 umbrella, 1 skis, 22.9ms\n",
            "Speed: 3.6ms preprocess, 22.9ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 persons, 1 umbrella, 23.2ms\n",
            "Speed: 2.7ms preprocess, 23.2ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.3ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.6ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.8ms\n",
            "Speed: 3.6ms preprocess, 22.8ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.8ms\n",
            "Speed: 2.6ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.8ms\n",
            "Speed: 2.5ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.2ms preprocess, 22.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.8ms\n",
            "Speed: 3.6ms preprocess, 22.8ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.4ms preprocess, 22.9ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 23.0ms\n",
            "Speed: 3.7ms preprocess, 23.0ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 23.0ms\n",
            "Speed: 3.1ms preprocess, 23.0ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.6ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.8ms\n",
            "Speed: 2.6ms preprocess, 22.8ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.6ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.8ms\n",
            "Speed: 2.8ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 1 skateboard, 23.0ms\n",
            "Speed: 3.6ms preprocess, 23.0ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.5ms preprocess, 22.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.8ms\n",
            "Speed: 2.6ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 23.5ms\n",
            "Speed: 2.8ms preprocess, 23.5ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.8ms\n",
            "Speed: 3.4ms preprocess, 22.8ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.8ms\n",
            "Speed: 3.6ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.0ms preprocess, 22.9ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.6ms preprocess, 22.9ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.1ms preprocess, 22.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 1 skateboard, 22.8ms\n",
            "Speed: 2.7ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 1 skateboard, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.0ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.8ms\n",
            "Speed: 3.5ms preprocess, 22.8ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.4ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.5ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.8ms\n",
            "Speed: 3.5ms preprocess, 22.8ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.6ms preprocess, 22.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.6ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 23.6ms\n",
            "Speed: 5.5ms preprocess, 23.6ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.5ms preprocess, 22.9ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.5ms preprocess, 22.9ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.4ms preprocess, 22.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 23.0ms\n",
            "Speed: 2.9ms preprocess, 23.0ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.8ms\n",
            "Speed: 2.7ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.3ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.6ms preprocess, 22.9ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.8ms\n",
            "Speed: 3.7ms preprocess, 22.8ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.8ms\n",
            "Speed: 3.1ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 23.5ms\n",
            "Speed: 2.8ms preprocess, 23.5ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.9ms preprocess, 22.9ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 23.8ms\n",
            "Speed: 3.2ms preprocess, 23.8ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.6ms preprocess, 22.9ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 25.7ms\n",
            "Speed: 3.4ms preprocess, 25.7ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.9ms preprocess, 22.9ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.9ms\n",
            "Speed: 4.9ms preprocess, 22.9ms inference, 4.3ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 5 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.6ms preprocess, 22.9ms inference, 3.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 4 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.9ms preprocess, 22.9ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 4 persons, 1 umbrella, 25.0ms\n",
            "Speed: 2.8ms preprocess, 25.0ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 5 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 4 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.7ms preprocess, 22.9ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 4 persons, 1 umbrella, 23.9ms\n",
            "Speed: 4.5ms preprocess, 23.9ms inference, 4.2ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 4 persons, 1 umbrella, 22.9ms\n",
            "Speed: 5.4ms preprocess, 22.9ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 4 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 4 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.9ms preprocess, 22.9ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 5 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.9ms preprocess, 22.9ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 5 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.9ms preprocess, 22.9ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 23.3ms\n",
            "Speed: 2.8ms preprocess, 23.3ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.9ms\n",
            "Speed: 5.9ms preprocess, 22.9ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 23.6ms\n",
            "Speed: 2.7ms preprocess, 23.6ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 24.4ms\n",
            "Speed: 3.8ms preprocess, 24.4ms inference, 3.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 23.0ms\n",
            "Speed: 3.5ms preprocess, 23.0ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 24.4ms\n",
            "Speed: 2.8ms preprocess, 24.4ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 23.7ms\n",
            "Speed: 2.9ms preprocess, 23.7ms inference, 2.3ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 persons, 1 umbrella, 22.9ms\n",
            "Speed: 5.4ms preprocess, 22.9ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 persons, 1 umbrella, 23.0ms\n",
            "Speed: 2.7ms preprocess, 23.0ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.1ms preprocess, 22.9ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 persons, 1 umbrella, 23.0ms\n",
            "Speed: 3.3ms preprocess, 23.0ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 9 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.0ms preprocess, 22.9ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.1ms preprocess, 22.9ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 26.6ms\n",
            "Speed: 4.3ms preprocess, 26.6ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 23.8ms\n",
            "Speed: 3.8ms preprocess, 23.8ms inference, 3.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 23.0ms\n",
            "Speed: 2.8ms preprocess, 23.0ms inference, 2.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 23.0ms\n",
            "Speed: 3.0ms preprocess, 23.0ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 24.1ms\n",
            "Speed: 3.1ms preprocess, 24.1ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 1 skateboard, 23.0ms\n",
            "Speed: 3.5ms preprocess, 23.0ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.5ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.6ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 23.2ms\n",
            "Speed: 3.1ms preprocess, 23.2ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 1 skateboard, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 1 skateboard, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 2 skateboards, 22.9ms\n",
            "Speed: 3.0ms preprocess, 22.9ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 2 skateboards, 22.9ms\n",
            "Speed: 3.4ms preprocess, 22.9ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 1 skateboard, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.6ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 23.0ms\n",
            "Speed: 3.0ms preprocess, 23.0ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 1 skateboard, 23.4ms\n",
            "Speed: 3.4ms preprocess, 23.4ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.8ms\n",
            "Speed: 2.8ms preprocess, 22.8ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 23.0ms\n",
            "Speed: 3.7ms preprocess, 23.0ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.0ms preprocess, 22.9ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.9ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.8ms\n",
            "Speed: 2.8ms preprocess, 22.8ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.7ms preprocess, 22.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.5ms preprocess, 22.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.8ms\n",
            "Speed: 3.7ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.9ms preprocess, 22.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.8ms\n",
            "Speed: 2.7ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.8ms\n",
            "Speed: 2.7ms preprocess, 22.8ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.4ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 23.0ms\n",
            "Speed: 3.4ms preprocess, 23.0ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.9ms\n",
            "Speed: 4.9ms preprocess, 22.9ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.9ms\n",
            "Speed: 4.2ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.0ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.1ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.8ms\n",
            "Speed: 2.8ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.5ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.8ms\n",
            "Speed: 2.9ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.6ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.8ms\n",
            "Speed: 2.6ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.4ms preprocess, 22.9ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 23.0ms\n",
            "Speed: 5.4ms preprocess, 23.0ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.8ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.9ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.8ms\n",
            "Speed: 3.6ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.5ms preprocess, 22.9ms inference, 2.2ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.9ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.2ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 23.1ms\n",
            "Speed: 2.8ms preprocess, 23.1ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 23.0ms\n",
            "Speed: 2.9ms preprocess, 23.0ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.9ms preprocess, 22.9ms inference, 2.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.7ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.8ms preprocess, 22.9ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.9ms\n",
            "Speed: 4.8ms preprocess, 22.9ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.9ms\n",
            "Speed: 4.8ms preprocess, 22.9ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 1 skateboard, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 1.7ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.9ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.4ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 motorcycle, 1 umbrella, 23.0ms\n",
            "Speed: 3.6ms preprocess, 23.0ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 1 skateboard, 23.6ms\n",
            "Speed: 3.4ms preprocess, 23.6ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 1 skateboard, 22.9ms\n",
            "Speed: 3.5ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 1 skateboard, 22.9ms\n",
            "Speed: 3.5ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 23.0ms\n",
            "Speed: 3.5ms preprocess, 23.0ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.3ms preprocess, 22.9ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 1 skateboard, 23.0ms\n",
            "Speed: 4.7ms preprocess, 23.0ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 1 skateboard, 22.9ms\n",
            "Speed: 3.4ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 1 skateboard, 22.9ms\n",
            "Speed: 2.9ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.8ms\n",
            "Speed: 2.9ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 8 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.4ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 23.0ms\n",
            "Speed: 3.6ms preprocess, 23.0ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.0ms preprocess, 22.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.9ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.9ms preprocess, 22.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.8ms\n",
            "Speed: 2.7ms preprocess, 22.8ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.0ms preprocess, 22.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.8ms\n",
            "Speed: 3.0ms preprocess, 22.8ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 1 skateboard, 23.3ms\n",
            "Speed: 7.9ms preprocess, 23.3ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.0ms preprocess, 22.9ms inference, 2.0ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 23.1ms\n",
            "Speed: 2.8ms preprocess, 23.1ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 6 persons, 1 umbrella, 22.8ms\n",
            "Speed: 2.9ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 5 persons, 1 bicycle, 1 umbrella, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 5 persons, 1 bicycle, 1 umbrella, 23.6ms\n",
            "Speed: 3.1ms preprocess, 23.6ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 5 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.9ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 1.6ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 23.0ms\n",
            "Speed: 2.8ms preprocess, 23.0ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 7 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 2.9ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 5 persons, 1 umbrella, 22.8ms\n",
            "Speed: 3.0ms preprocess, 22.8ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 5 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.8ms preprocess, 22.9ms inference, 1.9ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 5 persons, 1 umbrella, 23.0ms\n",
            "Speed: 3.6ms preprocess, 23.0ms inference, 2.1ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 5 persons, 1 umbrella, 23.0ms\n",
            "Speed: 3.4ms preprocess, 23.0ms inference, 1.8ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 5 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.3ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 5 persons, 1 umbrella, 22.9ms\n",
            "Speed: 2.9ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 5 persons, 1 umbrella, 23.8ms\n",
            "Speed: 2.6ms preprocess, 23.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 5 persons, 1 umbrella, 22.9ms\n",
            "Speed: 4.1ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 5 persons, 1 umbrella, 1 skateboard, 22.9ms\n",
            "Speed: 2.7ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 5 persons, 1 umbrella, 1 skateboard, 22.9ms\n",
            "Speed: 3.3ms preprocess, 22.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 5 persons, 1 umbrella, 1 skateboard, 22.9ms\n",
            "Speed: 3.0ms preprocess, 22.9ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 5 persons, 1 umbrella, 23.0ms\n",
            "Speed: 2.8ms preprocess, 23.0ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 5 persons, 1 umbrella, 22.8ms\n",
            "Speed: 3.0ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 5 persons, 1 umbrella, 23.1ms\n",
            "Speed: 2.6ms preprocess, 23.1ms inference, 1.5ms postprocess per image at shape (1, 3, 320, 640)\n",
            "\n",
            "0: 320x640 5 persons, 1 umbrella, 22.9ms\n",
            "Speed: 3.0ms preprocess, 22.9ms inference, 1.4ms postprocess per image at shape (1, 3, 320, 640)\n",
            "Video saved as: /content/processed_output3.avi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/<lakhangudigar>/<OpenCv>.git\n"
      ],
      "metadata": {
        "id": "NFnC-NeozilP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73c7b95f-385b-439a-c253-eff9c422eb48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: lakhangudigar: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mLf35t5OxQx5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}